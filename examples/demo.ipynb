{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Lattice v0.3 — Phase 2 Demo\n\nThis notebook demonstrates the full Lattice pipeline API with a tiny dataset (3 rows, ~$0.001 total cost).\n\n**What you'll see:**\n- `Pipeline.run(df)` / `pipeline.run_async(df)` — the primary API\n- Inline field specs on LLMStep\n- `PipelineResult` with cost tracking and error reporting\n- Multi-step pipelines with FunctionStep + LLMStep\n- Per-row error handling (one row fails, others succeed)\n- Progress bars via tqdm\n\n> **Note:** Jupyter runs its own async event loop, so we use `await pipeline.run_async(df)` here.\n> In scripts, use `pipeline.run(df)` (sync wrapper) instead."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lattice import Pipeline, LLMStep, FunctionStep, EnrichmentConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple: One LLM step with inline fields\n",
    "\n",
    "The simplest possible usage — 3 rows, 2 fields, one API call per row.\n",
    "\n",
    "Uses `gpt-4.1-nano` by default ($0.10/1M input, $0.40/1M output) — this cell costs ~$0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"company\": [\"Stripe\", \"Notion\", \"Figma\"],\n",
    "    \"description\": [\n",
    "        \"Online payment processing for internet businesses\",\n",
    "        \"All-in-one workspace for notes, docs, and project management\",\n",
    "        \"Collaborative interface design tool for teams\",\n",
    "    ],\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "pipeline = Pipeline([\n    LLMStep(\"analyze\", fields={\n        \"category\": \"Classify into one of: Fintech, Productivity, Design, Other\",\n        \"target_market\": \"Describe the primary target market in 10 words or less\",\n    })\n])\n\nresult = await pipeline.run_async(df)\nresult.data"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost and error summary\n",
    "print(f\"Success rate: {result.success_rate:.0%}\")\n",
    "print(f\"Errors: {len(result.errors)}\")\n",
    "print(f\"Total tokens: {result.cost.total_tokens}\")\n",
    "print(f\"\\nPer-step breakdown:\")\n",
    "for step_name, usage in result.cost.steps.items():\n",
    "    print(f\"  {step_name}: {usage.total_tokens} tokens ({usage.rows_processed} rows, model={usage.model})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multi-step pipeline with dependencies\n",
    "\n",
    "FunctionStep generates context → LLMStep uses it. Shows dependency routing and `__` internal fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def generate_context(ctx):\n    \"\"\"Simulate an API lookup — in production this could be a web search, CRM call, etc.\"\"\"\n    fake_data = {\n        \"Stripe\": \"Founded 2010. $95B valuation. 8000+ employees. Competes with Adyen, Square.\",\n        \"Notion\": \"Founded 2013. $10B valuation. 500+ employees. Competes with Confluence, Coda.\",\n        \"Figma\": \"Founded 2012. Acquired by Adobe for $20B (cancelled). Competes with Sketch, Canva.\",\n    }\n    company = ctx.row[\"company\"]\n    return {\"__context\": fake_data.get(company, \"No data available\")}\n\n\npipeline = Pipeline([\n    FunctionStep(\"lookup\", fn=generate_context, fields=[\"__context\"]),\n    LLMStep(\"synthesize\", fields={\n        \"competitive_position\": \"Rate as Leader/Challenger/Niche based on the context\",\n        \"investment_thesis\": \"One-sentence investment thesis using context and description\",\n    }, depends_on=[\"lookup\"]),\n])\n\nresult = await pipeline.run_async(df)\nresult.data"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __context is NOT in the output — internal fields are filtered\n",
    "print(\"Columns:\", list(result.data.columns))\n",
    "assert \"__context\" not in result.data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Per-row error handling\n",
    "\n",
    "One row throws an error — the other rows still complete. No crash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def flaky_lookup(ctx):\n    \"\"\"Simulates an API that fails for one company.\"\"\"\n    if ctx.row[\"company\"] == \"Notion\":\n        raise ConnectionError(\"API timeout for Notion\")\n    return {\"status\": f\"{ctx.row['company']} OK\"}\n\n\npipeline = Pipeline([\n    FunctionStep(\"check\", fn=flaky_lookup, fields=[\"status\"]),\n])\n\nresult = await pipeline.run_async(df)\n\nprint(f\"Success rate: {result.success_rate:.0%}\")\nprint(f\"Errors: {len(result.errors)}\")\nfor err in result.errors:\n    print(f\"  Row {err.row_index} ({df.iloc[err.row_index]['company']}): {err.error_type} — {err.error}\")\n\nresult.data[[\"company\", \"status\"]]"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Custom config\n",
    "\n",
    "Control concurrency, retries, progress bars, and error mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "config = EnrichmentConfig(\n    max_workers=2,           # concurrent rows\n    temperature=0.1,         # low for deterministic output\n    max_retries=2,           # API error retries\n    enable_progress_bar=True,\n)\n\npipeline = Pipeline([\n    LLMStep(\"tag\", fields={\n        \"keywords\": \"List 3 keywords as a comma-separated string\",\n    })\n])\n\nresult = await pipeline.run_async(df, config=config)\nresult.data[[\"company\", \"keywords\"]]"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Using a different provider (base_url)\n",
    "\n",
    "Any OpenAI-compatible API works via `base_url`. Uncomment one of these to try:\n",
    "\n",
    "```python\n",
    "# Ollama (local)\n",
    "LLMStep(\"analyze\", fields={...}, model=\"llama3\", base_url=\"http://localhost:11434/v1\")\n",
    "\n",
    "# Groq\n",
    "LLMStep(\"analyze\", fields={...}, model=\"llama-3.3-70b-versatile\", base_url=\"https://api.groq.com/openai/v1\", api_key=\"gsk_...\")\n",
    "\n",
    "# Anthropic (requires: pip install lattice[anthropic])\n",
    "from lattice.providers import AnthropicClient\n",
    "LLMStep(\"analyze\", fields={...}, model=\"claude-sonnet-4-5-20250929\", client=AnthropicClient())\n",
    "\n",
    "# Google (requires: pip install lattice[google])\n",
    "from lattice.providers import GoogleClient\n",
    "LLMStep(\"analyze\", fields={...}, model=\"gemini-2.5-flash\", client=GoogleClient())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Feature | How |\n",
    "|---------|-----|\n",
    "| Run pipeline | `pipeline.run(df)` → `PipelineResult` |\n",
    "| Inline fields | `LLMStep(\"name\", fields={\"field\": \"prompt\"})` |\n",
    "| Cost tracking | `result.cost.total_tokens`, `result.cost.steps` |\n",
    "| Error handling | `result.errors`, `result.success_rate` |\n",
    "| Multi-step | `depends_on=[\"step_name\"]` |\n",
    "| Internal fields | `__` prefix — filtered from output |\n",
    "| Providers | `base_url=`, `client=AnthropicClient()` |\n",
    "| Config | `EnrichmentConfig(max_workers=10, temperature=0.1)` |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}