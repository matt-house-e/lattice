{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Lattice v0.4 Demo\n",
    "\n",
    "This notebook demonstrates the Lattice pipeline across **Phases 2, 3, and 4**.\n",
    "\n",
    "**Phase 2 — Resilience & API redesign:**\n",
    "- `Pipeline.run(df)` returns `PipelineResult` with `.data`, `.cost`, `.errors`, `.success_rate`\n",
    "- Per-step cost aggregation (`CostSummary` with token counts per step)\n",
    "- Per-row error handling (`on_error=\"continue\"` / `\"raise\"`, `RowError`)\n",
    "- `EnrichmentConfig` presets (`for_development()`, `for_production()`, `for_server()`)\n",
    "- Provider flexibility via `base_url` shortcut and `LLMClient` protocol\n",
    "- tqdm progress bar per step\n",
    "- Two-layer retry: API errors (429/500) with backoff + parse errors fed back to the LLM\n",
    "\n",
    "**Phase 3 — Field spec & dynamic prompts:**\n",
    "- 7-key field spec: `prompt`, `type`, `format`, `enum`, `examples`, `bad_examples`, `default`\n",
    "- Dynamic prompt builder (markdown headers + XML data boundaries)\n",
    "- Default enforcement — refusals replaced with field `default` in Python\n",
    "- FieldSpec validation — unknown keys rejected at construction time\n",
    "\n",
    "**Phase 4 — Caching & `list[dict]` input:**\n",
    "- SQLite-backed input-hash cache (`enable_caching=True`) — skip redundant API calls\n",
    "- Per-step cache stats: `cache_hits`, `cache_misses`, `cache_hit_rate`\n",
    "- `pipeline.clear_cache()` for full or per-step invalidation\n",
    "- `list[dict]` input: `pipeline.run([{...}])` returns `list[dict]` (output matches input type)\n",
    "- `FunctionStep(..., cache=False)` to disable caching for non-deterministic steps\n",
    "\n",
    "> **Note:** Jupyter runs its own event loop, so we use `await pipeline.run_async(df)`.\n",
    "> In scripts, use `pipeline.run(df)` (sync wrapper) instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:19:21.117605Z",
     "iopub.status.busy": "2026-02-20T12:19:21.117405Z",
     "iopub.status.idle": "2026-02-20T12:19:23.172105Z",
     "shell.execute_reply": "2026-02-20T12:19:23.171832Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthew.house/Programming/lattice/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from lattice import Pipeline, LLMStep, FunctionStep, EnrichmentConfig, FieldSpec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s1-header",
   "metadata": {},
   "source": [
    "## 1. Pipeline.run() → PipelineResult (Phase 2)\n",
    "\n",
    "`Pipeline.run(df)` is the primary API. It returns a `PipelineResult` with:\n",
    "- `.data` — enriched DataFrame\n",
    "- `.cost` — `CostSummary` with per-step token usage\n",
    "- `.errors` — list of `RowError` objects\n",
    "- `.success_rate` — fraction of rows that succeeded\n",
    "- `.has_errors` — quick boolean check\n",
    "\n",
    "The simplest case: 3 rows, 2 fields, one LLM call per row. Default model is `gpt-4.1-mini`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "s1-data",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:19:23.173658Z",
     "iopub.status.busy": "2026-02-20T12:19:23.173535Z",
     "iopub.status.idle": "2026-02-20T12:19:23.183503Z",
     "shell.execute_reply": "2026-02-20T12:19:23.183239Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stripe</td>\n",
       "      <td>Online payment processing for internet businesses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Notion</td>\n",
       "      <td>All-in-one workspace for notes, docs, and proj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Figma</td>\n",
       "      <td>Collaborative interface design tool for teams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company                                        description\n",
       "0  Stripe  Online payment processing for internet businesses\n",
       "1  Notion  All-in-one workspace for notes, docs, and proj...\n",
       "2   Figma      Collaborative interface design tool for teams"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"company\": [\"Stripe\", \"Notion\", \"Figma\"],\n",
    "    \"description\": [\n",
    "        \"Online payment processing for internet businesses\",\n",
    "        \"All-in-one workspace for notes, docs, and project management\",\n",
    "        \"Collaborative interface design tool for teams\",\n",
    "    ],\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "s1-run",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:19:23.184735Z",
     "iopub.status.busy": "2026-02-20T12:19:23.184656Z",
     "iopub.status.idle": "2026-02-20T12:19:25.054504Z",
     "shell.execute_reply": "2026-02-20T12:19:25.054239Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Pipeline:   0%|          | 0/1 [00:00<?, ?step/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Pipeline:   0%|          | 0/1 [00:00<?, ?step/s, step=analyze]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90mlattice.pipeline.pipeline\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | Row 0 failed in step 'analyze': The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90mlattice.pipeline.pipeline\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | Row 1 failed in step 'analyze': The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90mlattice.pipeline.pipeline\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | Row 2 failed in step 'analyze': The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Pipeline: 100%|██████████| 1/1 [00:01<00:00,  1.84s/step, step=analyze]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Pipeline: 100%|██████████| 1/1 [00:01<00:00,  1.84s/step, step=analyze]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "      <th>target_market</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stripe</td>\n",
       "      <td>Online payment processing for internet businesses</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Notion</td>\n",
       "      <td>All-in-one workspace for notes, docs, and proj...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Figma</td>\n",
       "      <td>Collaborative interface design tool for teams</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company                                        description category  \\\n",
       "0  Stripe  Online payment processing for internet businesses     None   \n",
       "1  Notion  All-in-one workspace for notes, docs, and proj...     None   \n",
       "2   Figma      Collaborative interface design tool for teams     None   \n",
       "\n",
       "  target_market  \n",
       "0          None  \n",
       "1          None  \n",
       "2          None  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    LLMStep(\"analyze\", fields={\n",
    "        \"category\": \"Classify into one of: Fintech, Productivity, Design, Other\",\n",
    "        \"target_market\": \"Describe the primary target market in 10 words or less\",\n",
    "    })\n",
    "])\n",
    "\n",
    "result = await pipeline.run_async(df)\n",
    "result.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "s1-cost",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:19:25.055911Z",
     "iopub.status.busy": "2026-02-20T12:19:25.055789Z",
     "iopub.status.idle": "2026-02-20T12:19:25.057985Z",
     "shell.execute_reply": "2026-02-20T12:19:25.057760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate: 0%\n",
      "Has errors:   True\n",
      "Total tokens: 0\n",
      "  Prompt:     0\n",
      "  Completion: 0\n",
      "\n",
      "Per-step breakdown:\n"
     ]
    }
   ],
   "source": [
    "# PipelineResult gives you everything in one object\n",
    "print(f\"Success rate: {result.success_rate:.0%}\")\n",
    "print(f\"Has errors:   {result.has_errors}\")\n",
    "print(f\"Total tokens: {result.cost.total_tokens}\")\n",
    "print(f\"  Prompt:     {result.cost.total_prompt_tokens}\")\n",
    "print(f\"  Completion: {result.cost.total_completion_tokens}\")\n",
    "\n",
    "print(f\"\\nPer-step breakdown:\")\n",
    "for step_name, usage in result.cost.steps.items():\n",
    "    print(f\"  {step_name}: {usage.total_tokens} tokens, {usage.rows_processed} rows, model={usage.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s2-header",
   "metadata": {},
   "source": [
    "## 2. Per-row error handling (Phase 2)\n",
    "\n",
    "With `on_error=\"continue\"` (the default), failed rows don't crash the pipeline.\n",
    "They produce `RowError` objects with sentinel `None` values, and the rest of the rows succeed normally.\n",
    "\n",
    "With `on_error=\"raise\"`, the pipeline fails fast on the first error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "s2-error-demo",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:19:25.059509Z",
     "iopub.status.busy": "2026-02-20T12:19:25.059392Z",
     "iopub.status.idle": "2026-02-20T12:19:25.065357Z",
     "shell.execute_reply": "2026-02-20T12:19:25.065112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90mlattice.pipeline.pipeline\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | Row 1 failed in step 'lookup': API timeout for Notion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate: 67%\n",
      "Errors: 1\n",
      "\n",
      "  Row 1 (Notion): ConnectionError — API timeout for Notion\n",
      "\n",
      "Data (failed rows get None sentinels):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stripe</td>\n",
       "      <td>Stripe found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Notion</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Figma</td>\n",
       "      <td>Figma found</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company        status\n",
       "0  Stripe  Stripe found\n",
       "1  Notion          None\n",
       "2   Figma   Figma found"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def flaky_lookup(ctx):\n",
    "    \"\"\"Simulates an API that fails for unknown companies.\"\"\"\n",
    "    company = ctx.row[\"company\"]\n",
    "    if company == \"Notion\":\n",
    "        raise ConnectionError(f\"API timeout for {company}\")\n",
    "    return {\"status\": f\"{company} found\"}\n",
    "\n",
    "\n",
    "pipeline_err = Pipeline([\n",
    "    FunctionStep(\"lookup\", fn=flaky_lookup, fields=[\"status\"]),\n",
    "])\n",
    "\n",
    "config = EnrichmentConfig(enable_progress_bar=False, on_error=\"continue\")\n",
    "result = await pipeline_err.run_async(df, config)\n",
    "\n",
    "print(f\"Success rate: {result.success_rate:.0%}\")\n",
    "print(f\"Errors: {len(result.errors)}\\n\")\n",
    "\n",
    "for err in result.errors:\n",
    "    print(f\"  Row {err.row_index} ({df.iloc[err.row_index]['company']}): \"\n",
    "          f\"{err.error_type} \\u2014 {err.error}\")\n",
    "\n",
    "print(f\"\\nData (failed rows get None sentinels):\")\n",
    "result.data[[\"company\", \"status\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "s2-raise-demo",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:19:25.066455Z",
     "iopub.status.busy": "2026-02-20T12:19:25.066383Z",
     "iopub.status.idle": "2026-02-20T12:19:25.069371Z",
     "shell.execute_reply": "2026-02-20T12:19:25.069143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90mlattice.pipeline.pipeline\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | Row 1 failed in step 'lookup': API timeout for Notion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline stopped immediately: API timeout for Notion\n"
     ]
    }
   ],
   "source": [
    "# on_error=\"raise\" fails fast on the first error\n",
    "from lattice.core.exceptions import RowError\n",
    "\n",
    "config_raise = EnrichmentConfig(enable_progress_bar=False, on_error=\"raise\")\n",
    "try:\n",
    "    await pipeline_err.run_async(df, config_raise)\n",
    "except ConnectionError as e:\n",
    "    print(f\"Pipeline stopped immediately: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s3-header",
   "metadata": {},
   "source": [
    "## 3. EnrichmentConfig presets (Phase 2)\n",
    "\n",
    "Three built-in presets cover common scenarios. Each tunes concurrency, logging, caching, and checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "s3-presets",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:19:25.070711Z",
     "iopub.status.busy": "2026-02-20T12:19:25.070634Z",
     "iopub.status.idle": "2026-02-20T12:19:25.073399Z",
     "shell.execute_reply": "2026-02-20T12:19:25.073131Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for_development():\n",
      "  max_workers = 5\n",
      "  log_level = 'DEBUG'\n",
      "  enable_caching = True\n",
      "\n",
      "for_production():\n",
      "  max_workers = 30\n",
      "  max_retries = 5\n",
      "  enable_checkpointing = True\n",
      "  enable_caching = True\n",
      "  checkpoint_interval = 100\n",
      "\n",
      "for_server():\n",
      "  max_workers = 30\n",
      "  max_retries = 5\n",
      "  log_level = 'WARNING'\n",
      "  enable_progress_bar = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import asdict\n",
    "\n",
    "for name, preset in [\n",
    "    (\"for_development()\", EnrichmentConfig.for_development()),\n",
    "    (\"for_production()\",  EnrichmentConfig.for_production()),\n",
    "    (\"for_server()\",      EnrichmentConfig.for_server()),\n",
    "]:\n",
    "    d = asdict(preset)\n",
    "    print(f\"{name}:\")\n",
    "    # Show only the fields that differ from defaults\n",
    "    defaults = asdict(EnrichmentConfig())\n",
    "    diff = {k: v for k, v in d.items() if v != defaults[k]}\n",
    "    for k, v in diff.items():\n",
    "        print(f\"  {k} = {v!r}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s4-header",
   "metadata": {},
   "source": [
    "## 4. Provider flexibility (Phase 2)\n",
    "\n",
    "LLMStep uses the `LLMClient` protocol. OpenAI is the default (zero config).\n",
    "The `base_url` shortcut works with any OpenAI-compatible provider.\n",
    "Anthropic and Google ship as optional extras.\n",
    "\n",
    "```python\n",
    "# OpenAI-compatible providers (Ollama, Groq, DeepSeek, etc.)\n",
    "LLMStep(\"analyze\", fields={...}, model=\"llama3\", base_url=\"http://localhost:11434/v1\")\n",
    "\n",
    "# Anthropic: pip install lattice[anthropic]\n",
    "from lattice.providers import AnthropicClient\n",
    "LLMStep(\"analyze\", fields={...}, model=\"claude-sonnet-4-5-20250929\", client=AnthropicClient())\n",
    "\n",
    "# Google: pip install lattice[google]\n",
    "from lattice.providers import GoogleClient\n",
    "LLMStep(\"analyze\", fields={...}, model=\"gemini-2.5-flash\", client=GoogleClient())\n",
    "\n",
    "# Any provider — implement the ~30-line LLMClient protocol\n",
    "LLMStep(\"analyze\", fields={...}, client=MyCustomClient())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s5-header",
   "metadata": {},
   "source": [
    "## 5. Multi-step pipeline with cost tracking (Phase 2)\n",
    "\n",
    "FunctionStep generates context, LLMStep uses it via `depends_on`.\n",
    "Internal `__` fields are filtered from output. Cost tracks across all steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "s5-multi-step",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:19:25.074735Z",
     "iopub.status.busy": "2026-02-20T12:19:25.074655Z",
     "iopub.status.idle": "2026-02-20T12:19:25.084699Z",
     "shell.execute_reply": "2026-02-20T12:19:25.084255Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Pipeline:   0%|          | 0/2 [00:00<?, ?step/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Pipeline:   0%|          | 0/2 [00:00<?, ?step/s, step=lookup]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Pipeline:  50%|█████     | 1/2 [00:00<00:00, 705.16step/s, step=synthesize]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90mlattice.pipeline.pipeline\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | Row 0 failed in step 'synthesize': The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90mlattice.pipeline.pipeline\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | Row 1 failed in step 'synthesize': The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90mlattice.pipeline.pipeline\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | Row 2 failed in step 'synthesize': The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Pipeline: 100%|██████████| 2/2 [00:00<00:00, 742.35step/s, step=synthesize]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['company', 'description', 'competitive_position', 'investment_thesis']\n",
      "\n",
      "Cost across 0 steps:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>competitive_position</th>\n",
       "      <th>investment_thesis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stripe</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Notion</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Figma</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company competitive_position investment_thesis\n",
       "0  Stripe                 None              None\n",
       "1  Notion                 None              None\n",
       "2   Figma                 None              None"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_context(ctx):\n",
    "    \"\"\"Simulate an API lookup.\"\"\"\n",
    "    fake_data = {\n",
    "        \"Stripe\": \"Founded 2010. $95B valuation. 8000+ employees. Competes with Adyen, Square.\",\n",
    "        \"Notion\": \"Founded 2013. $10B valuation. 500+ employees. Competes with Confluence, Coda.\",\n",
    "        \"Figma\": \"Founded 2012. Acquired by Adobe for $20B (cancelled). Competes with Sketch, Canva.\",\n",
    "    }\n",
    "    company = ctx.row[\"company\"]\n",
    "    return {\"__context\": fake_data.get(company, \"No data available\")}\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    FunctionStep(\"lookup\", fn=generate_context, fields=[\"__context\"]),\n",
    "    LLMStep(\"synthesize\", fields={\n",
    "        \"competitive_position\": {\n",
    "            \"prompt\": \"Rate the company's competitive position based on the context\",\n",
    "            \"enum\": [\"Leader\", \"Challenger\", \"Niche\"],\n",
    "        },\n",
    "        \"investment_thesis\": \"One-sentence investment thesis using context and description\",\n",
    "    }, depends_on=[\"lookup\"]),\n",
    "])\n",
    "\n",
    "result = await pipeline.run_async(df)\n",
    "\n",
    "print(\"Columns:\", list(result.data.columns))\n",
    "assert \"__context\" not in result.data.columns  # internal fields filtered\n",
    "\n",
    "print(f\"\\nCost across {len(result.cost.steps)} steps:\")\n",
    "for step_name, usage in result.cost.steps.items():\n",
    "    print(f\"  {step_name}: {usage.total_tokens} tokens, {usage.rows_processed} rows\")\n",
    "\n",
    "result.data[[\"company\", \"competitive_position\", \"investment_thesis\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s6-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Full 7-key field spec (Phase 3)\n",
    "\n",
    "Each field can use up to 7 keys:\n",
    "- `prompt` (required) — the extraction instruction\n",
    "- `type` — String, Number, Boolean, Date, List[String], JSON\n",
    "- `format` — output format pattern\n",
    "- `enum` — constrained value list (LLM MUST pick one)\n",
    "- `examples` — good output examples\n",
    "- `bad_examples` — anti-patterns to avoid\n",
    "- `default` — fallback when data is insufficient (enforced in Python, not by the LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "s6-field-spec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:19:25.086062Z",
     "iopub.status.busy": "2026-02-20T12:19:25.085964Z",
     "iopub.status.idle": "2026-02-20T12:19:25.093599Z",
     "shell.execute_reply": "2026-02-20T12:19:25.093326Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Pipeline:   0%|          | 0/1 [00:00<?, ?step/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Pipeline:   0%|          | 0/1 [00:00<?, ?step/s, step=enrich]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90mlattice.pipeline.pipeline\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | Row 0 failed in step 'enrich': The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90mlattice.pipeline.pipeline\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | Row 1 failed in step 'enrich': The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90mlattice.pipeline.pipeline\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | Row 2 failed in step 'enrich': The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Pipeline: 100%|██████████| 1/1 [00:00<00:00, 861.25step/s, step=enrich]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>sector</th>\n",
       "      <th>employee_count</th>\n",
       "      <th>growth_stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stripe</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Notion</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Figma</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company sector employee_count growth_stage\n",
       "0  Stripe   None           None         None\n",
       "1  Notion   None           None         None\n",
       "2   Figma   None           None         None"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    LLMStep(\"enrich\", fields={\n",
    "        \"sector\": {\n",
    "            \"prompt\": \"Classify the company's primary sector\",\n",
    "            \"enum\": [\"Fintech\", \"Productivity\", \"Design\", \"Infrastructure\", \"Other\"],\n",
    "            \"examples\": [\"Fintech\", \"Productivity\"],\n",
    "            \"bad_examples\": [\"Tech company\", \"Software\"],\n",
    "            \"default\": \"Other\",\n",
    "        },\n",
    "        \"employee_count\": {\n",
    "            \"prompt\": \"Estimate the number of employees\",\n",
    "            \"type\": \"Number\",\n",
    "            \"format\": \"integer\",\n",
    "            \"default\": 0,\n",
    "        },\n",
    "        \"growth_stage\": {\n",
    "            \"prompt\": \"Classify the company's growth stage based on its description and market position\",\n",
    "            \"enum\": [\"Seed\", \"Growth\", \"Mature\", \"Decline\"],\n",
    "            \"examples\": [\"Growth - rapidly expanding market share\"],\n",
    "            \"default\": \"Unknown\",\n",
    "        },\n",
    "    })\n",
    "])\n",
    "\n",
    "result = await pipeline.run_async(df)\n",
    "result.data[[\"company\", \"sector\", \"employee_count\", \"growth_stage\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "s6-prompt-inspect",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:19:25.094883Z",
     "iopub.status.busy": "2026-02-20T12:19:25.094806Z",
     "iopub.status.idle": "2026-02-20T12:19:25.096900Z",
     "shell.execute_reply": "2026-02-20T12:19:25.096624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Role\n",
      "You are a structured data enrichment engine. Given one input row, a set of field specifications, and optional context from prior processing steps, produce a JSON object with exactly the requested fields as keys.\n",
      "\n",
      "# Field Specification Keys\n",
      "Each field below is described using these keys:\n",
      "- **prompt**: the extraction instruction for this field\n",
      "- **type**: expected output data type (String, Number, Boolean, Date, List[String], JSON)\n",
      "- **format**: output format pattern to follow\n",
      "- **enum**: constrained value list — the output MUST be one of these options exactly\n",
      "- **examples**: good output examples showing expected style\n",
      "- **bad_examples**: anti-patterns to avoid\n",
      "- **default**: last-resort fallback if you truly cannot determine the value\n",
      "\n",
      "# Output Rules\n",
      "- Return ONLY a single valid JSON object. No prose, no code fences, no explanations.\n",
      "- Top-level keys MUST be exactly: sector, employee_count, growth_stage\n",
      "- Keep outputs concise and information-dense.\n",
      "- For enum fields, the value MUST match one of the listed options exactly. Do not paraphrase or combine options.\n",
      "- For fields with a format, follow the specified pattern precisely.\n",
      "- Always attempt to determine a value using the row data, prior results, and your general knowledge.\n",
      "- Only if you genuinely cannot determine a value after exhausting all available information, you may use the field's default value as a last resort.\n",
      "\n",
      "<row_data>\n",
      "{\"company\": \"Stripe\", \"description\": \"Online payment processing\"}\n",
      "</row_data>\n",
      "\n",
      "<field_specifications>\n",
      "<field name=\"sector\">\n",
      "  <prompt>Classify the company's primary sector</prompt>\n",
      "  <enum>Fintech, Productivity, Design, Infrastructure, Other</enum>\n",
      "  <example>Fintech</example>\n",
      "  <example>Productivity</example>\n",
      "  <bad_example>Tech company</bad_example>\n",
      "  <bad_example>Software</bad_example>\n",
      "  <default>Other</default>\n",
      "</field>\n",
      "<field name=\"employee_count\">\n",
      "  <prompt>Estimate the number of employees</prompt>\n",
      "  <type>Number</type>\n",
      "  <format>integer</format>\n",
      "  <default>0</default>\n",
      "</field>\n",
      "<field name=\"growth_stage\">\n",
      "  <prompt>Classify the company's growth stage based on its description and market position</prompt>\n",
      "  <enum>Seed, Growth, Mature, Decline</enum>\n",
      "  <example>Growth - rapidly expanding market share</example>\n",
      "  <default>Unknown</default>\n",
      "</field>\n",
      "</field_specifications>\n",
      "\n",
      "# Reminder\n",
      "Return ONLY the JSON object with keys: sector, employee_count, growth_stage. No additional text.\n"
     ]
    }
   ],
   "source": [
    "# Inspect the generated system prompt to see the dynamic builder in action\n",
    "from lattice.steps.prompt_builder import build_system_message\n",
    "\n",
    "step = pipeline.get_step(\"enrich\")\n",
    "sample_prompt = build_system_message(\n",
    "    field_specs=step._field_specs,\n",
    "    row={\"company\": \"Stripe\", \"description\": \"Online payment processing\"},\n",
    ")\n",
    "print(sample_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s7-header",
   "metadata": {},
   "source": [
    "## 7. Default enforcement (Phase 3)\n",
    "\n",
    "When the LLM can't determine a value, it returns refusal text like \"Unable to determine\".\n",
    "Default enforcement catches this in Python and replaces it with the field's `default`.\n",
    "\n",
    "We use a made-up company with no description to trigger refusals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "s7-defaults",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:19:25.098236Z",
     "iopub.status.busy": "2026-02-20T12:19:25.098152Z",
     "iopub.status.idle": "2026-02-20T12:19:25.104561Z",
     "shell.execute_reply": "2026-02-20T12:19:25.104344Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Pipeline:   0%|          | 0/1 [00:00<?, ?step/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Pipeline:   0%|          | 0/1 [00:00<?, ?step/s, step=analyze]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90mlattice.pipeline.pipeline\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | Row 0 failed in step 'analyze': The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90mlattice.pipeline.pipeline\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | Row 1 failed in step 'analyze': The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Pipeline: 100%|██████████| 1/1 [00:00<00:00, 992.97step/s, step=analyze]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>sector</th>\n",
       "      <th>founded_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stripe</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Xylophonica Dynamics Ltd</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    company sector founded_year\n",
       "0                    Stripe   None         None\n",
       "1  Xylophonica Dynamics Ltd   None         None"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unknown = pd.DataFrame({\n",
    "    \"company\": [\"Stripe\", \"Xylophonica Dynamics Ltd\"],\n",
    "    \"description\": [\n",
    "        \"Online payment processing for internet businesses\",\n",
    "        \"\",\n",
    "    ],\n",
    "})\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    LLMStep(\"analyze\", fields={\n",
    "        \"sector\": {\n",
    "            \"prompt\": \"What sector does this company operate in?\",\n",
    "            \"enum\": [\"Fintech\", \"SaaS\", \"Hardware\", \"Other\"],\n",
    "            \"default\": \"Unknown\",\n",
    "        },\n",
    "        \"founded_year\": {\n",
    "            \"prompt\": \"What year was this company founded?\",\n",
    "            \"type\": \"String\",\n",
    "            \"format\": \"YYYY\",\n",
    "            \"default\": \"N/A\",\n",
    "        },\n",
    "    })\n",
    "])\n",
    "\n",
    "result = await pipeline.run_async(df_unknown)\n",
    "result.data[[\"company\", \"sector\", \"founded_year\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s8-header",
   "metadata": {},
   "source": [
    "## 8. FieldSpec validation (Phase 3)\n",
    "\n",
    "Unknown keys are rejected at LLMStep construction time (not at runtime).\n",
    "This catches typos and legacy keys like `instructions` immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "s8-validation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:19:25.106211Z",
     "iopub.status.busy": "2026-02-20T12:19:25.106113Z",
     "iopub.status.idle": "2026-02-20T12:19:25.108250Z",
     "shell.execute_reply": "2026-02-20T12:19:25.108015Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught validation error (as expected):\n",
      "extra_forbidden — Extra inputs are not permitted\n"
     ]
    }
   ],
   "source": [
    "from pydantic import ValidationError\n",
    "\n",
    "# This SHOULD fail — \"instructions\" is not a valid key (use \"prompt\" instead)\n",
    "try:\n",
    "    LLMStep(\"bad\", fields={\n",
    "        \"f1\": {\"prompt\": \"test\", \"instructions\": \"extra guidance\"},\n",
    "    })\n",
    "except ValidationError as e:\n",
    "    print(\"Caught validation error (as expected):\")\n",
    "    print(e.errors()[0][\"type\"], \"\\u2014\", e.errors()[0][\"msg\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lawa735btzc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. SQLite-backed caching (Phase 4)\n",
    "\n",
    "With `enable_caching=True`, Lattice stores step results in a local SQLite database (`.lattice/cache.db`).\n",
    "The cache key is a SHA-256 hash of the step's full input: row data, prior results, field specs, model, and temperature.\n",
    "Changing any of these auto-invalidates the cache — no manual flushing needed.\n",
    "\n",
    "On the **first run**, all rows are cache misses (the step executes normally).\n",
    "On the **second run** with the same inputs, all rows are cache hits (zero API calls).\n",
    "\n",
    "Cache stats appear on `StepUsage`: `cache_hits`, `cache_misses`, and `cache_hit_rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dqygcze06o4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:19:25.109711Z",
     "iopub.status.busy": "2026-02-20T12:19:25.109611Z",
     "iopub.status.idle": "2026-02-20T12:19:25.129180Z",
     "shell.execute_reply": "2026-02-20T12:19:25.128953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== First run ===\n",
      "  Function called:  3 times\n",
      "  cache_hits:       0\n",
      "  cache_misses:     3\n",
      "  cache_hit_rate:   0%\n",
      "\n",
      "=== Second run (cached) ===\n",
      "  Function called:  0 times\n",
      "  cache_hits:       3\n",
      "  cache_misses:     0\n",
      "  cache_hit_rate:   100%\n",
      "\n",
      "Data matches between runs ✓\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stripe</td>\n",
       "      <td>Stripe: looked up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Notion</td>\n",
       "      <td>Notion: looked up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Figma</td>\n",
       "      <td>Figma: looked up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company               info\n",
       "0  Stripe  Stripe: looked up\n",
       "1  Notion  Notion: looked up\n",
       "2   Figma   Figma: looked up"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tempfile, os\n",
    "\n",
    "# Use a temp directory so the demo doesn't pollute the working directory\n",
    "cache_dir = tempfile.mkdtemp()\n",
    "\n",
    "call_count = 0\n",
    "\n",
    "def counted_lookup(ctx):\n",
    "    \"\"\"A FunctionStep that counts how many times it's actually called.\"\"\"\n",
    "    global call_count\n",
    "    call_count += 1\n",
    "    company = ctx.row[\"company\"]\n",
    "    return {\"info\": f\"{company}: looked up\"}\n",
    "\n",
    "\n",
    "pipeline_cached = Pipeline([\n",
    "    FunctionStep(\"lookup\", fn=counted_lookup, fields=[\"info\"]),\n",
    "])\n",
    "\n",
    "config_cache = EnrichmentConfig(\n",
    "    enable_caching=True,\n",
    "    cache_dir=cache_dir,\n",
    "    enable_progress_bar=False,\n",
    ")\n",
    "\n",
    "# --- First run: all cache misses ---\n",
    "call_count = 0\n",
    "result1 = await pipeline_cached.run_async(df, config_cache)\n",
    "\n",
    "usage1 = result1.cost.steps[\"lookup\"]\n",
    "print(\"=== First run ===\")\n",
    "print(f\"  Function called:  {call_count} times\")\n",
    "print(f\"  cache_hits:       {usage1.cache_hits}\")\n",
    "print(f\"  cache_misses:     {usage1.cache_misses}\")\n",
    "print(f\"  cache_hit_rate:   {usage1.cache_hit_rate:.0%}\")\n",
    "\n",
    "# --- Second run: all cache hits (zero function calls) ---\n",
    "call_count = 0\n",
    "result2 = await pipeline_cached.run_async(df, config_cache)\n",
    "\n",
    "usage2 = result2.cost.steps[\"lookup\"]\n",
    "print(\"\\n=== Second run (cached) ===\")\n",
    "print(f\"  Function called:  {call_count} times\")\n",
    "print(f\"  cache_hits:       {usage2.cache_hits}\")\n",
    "print(f\"  cache_misses:     {usage2.cache_misses}\")\n",
    "print(f\"  cache_hit_rate:   {usage2.cache_hit_rate:.0%}\")\n",
    "\n",
    "# Data is identical\n",
    "assert result1.data.equals(result2.data)\n",
    "print(\"\\nData matches between runs ✓\")\n",
    "result2.data[[\"company\", \"info\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g6cnpf8j1va",
   "metadata": {},
   "source": [
    "## 10. Cache invalidation and `clear_cache()` (Phase 4)\n",
    "\n",
    "`pipeline.clear_cache()` wipes all cached entries. `pipeline.clear_cache(step=\"name\")` wipes only one step.\n",
    "\n",
    "Caching also auto-invalidates when inputs change — if you modify a row's data or change a field spec,\n",
    "the cache key changes and the step re-executes for that row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "siomz0918fm",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:19:25.130396Z",
     "iopub.status.busy": "2026-02-20T12:19:25.130324Z",
     "iopub.status.idle": "2026-02-20T12:19:25.149254Z",
     "shell.execute_reply": "2026-02-20T12:19:25.149024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleared 3 cache entries\n",
      "\n",
      "After clear — cache_misses: 3, function called: 3 times\n"
     ]
    }
   ],
   "source": [
    "# clear_cache() returns the number of entries deleted\n",
    "deleted = pipeline_cached.clear_cache(cache_dir=cache_dir)\n",
    "print(f\"Cleared {deleted} cache entries\")\n",
    "\n",
    "# After clearing, the next run is all cache misses again\n",
    "call_count = 0\n",
    "result3 = await pipeline_cached.run_async(df, config_cache)\n",
    "usage3 = result3.cost.steps[\"lookup\"]\n",
    "print(f\"\\nAfter clear — cache_misses: {usage3.cache_misses}, function called: {call_count} times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "idsp3fnfcfh",
   "metadata": {},
   "source": [
    "## 11. `cache=False` per step (Phase 4)\n",
    "\n",
    "Non-deterministic FunctionSteps (e.g. current time, random sampling) should skip caching.\n",
    "Set `cache=False` on the step. FunctionSteps can also use `cache_version=\"v1\"` — bumping\n",
    "the version string invalidates all cached entries for that step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "uq5v0jt9csm",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:19:25.150504Z",
     "iopub.status.busy": "2026-02-20T12:19:25.150433Z",
     "iopub.status.idle": "2026-02-20T12:19:25.154673Z",
     "shell.execute_reply": "2026-02-20T12:19:25.154442Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1 scores: [17.0, 36.0, 89.0]\n",
      "Run 2 scores: [100.0, 70.0, 69.0]\n",
      "Different? True\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def random_score(ctx):\n",
    "    \"\"\"Non-deterministic — should NOT be cached.\"\"\"\n",
    "    return {\"score\": random.randint(1, 100)}\n",
    "\n",
    "\n",
    "pipeline_nocache = Pipeline([\n",
    "    FunctionStep(\"rand\", fn=random_score, fields=[\"score\"], cache=False),\n",
    "])\n",
    "\n",
    "# Even with caching enabled globally, this step always re-executes\n",
    "r1 = await pipeline_nocache.run_async(df, config_cache)\n",
    "r2 = await pipeline_nocache.run_async(df, config_cache)\n",
    "\n",
    "print(\"Run 1 scores:\", list(r1.data[\"score\"]))\n",
    "print(\"Run 2 scores:\", list(r2.data[\"score\"]))\n",
    "print(\"Different?\", not r1.data[\"score\"].equals(r2.data[\"score\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3sxqzkcad1h",
   "metadata": {},
   "source": [
    "## 12. `list[dict]` input (Phase 4)\n",
    "\n",
    "`Pipeline.run()` also accepts `list[dict]` — useful for server contexts, test code,\n",
    "or Polars users (`polars_df.to_dicts()`). The output type matches the input type:\n",
    "DataFrame in → DataFrame out, `list[dict]` in → `list[dict]` out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dungl4i7py",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:19:25.155875Z",
     "iopub.status.busy": "2026-02-20T12:19:25.155802Z",
     "iopub.status.idle": "2026-02-20T12:19:25.158590Z",
     "shell.execute_reply": "2026-02-20T12:19:25.158237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input type:  list\n",
      "Output type: list\n",
      "Success rate: 100%\n",
      "\n",
      "{'company': 'Stripe', 'description': 'Online payment processing', 'tag': 'stripe'}\n",
      "{'company': 'Notion', 'description': 'All-in-one workspace', 'tag': 'notion'}\n"
     ]
    }
   ],
   "source": [
    "# Pass list[dict] instead of DataFrame\n",
    "rows = [\n",
    "    {\"company\": \"Stripe\", \"description\": \"Online payment processing\"},\n",
    "    {\"company\": \"Notion\", \"description\": \"All-in-one workspace\"},\n",
    "]\n",
    "\n",
    "pipeline_simple = Pipeline([\n",
    "    FunctionStep(\"tag\", fn=lambda ctx: {\"tag\": ctx.row[\"company\"].lower()}, fields=[\"tag\"]),\n",
    "])\n",
    "\n",
    "config_quiet = EnrichmentConfig(enable_progress_bar=False)\n",
    "result = await pipeline_simple.run_async(rows, config_quiet)\n",
    "\n",
    "# Output is list[dict], not DataFrame\n",
    "print(f\"Input type:  {type(rows).__name__}\")\n",
    "print(f\"Output type: {type(result.data).__name__}\")\n",
    "print(f\"Success rate: {result.success_rate:.0%}\\n\")\n",
    "\n",
    "for row in result.data:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10nnecvgdh7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:19:25.159836Z",
     "iopub.status.busy": "2026-02-20T12:19:25.159759Z",
     "iopub.status.idle": "2026-02-20T12:19:25.162427Z",
     "shell.execute_reply": "2026-02-20T12:19:25.162158Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cleanup temp cache directory\n",
    "import shutil\n",
    "shutil.rmtree(cache_dir, ignore_errors=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
