{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Conditional Step Execution (`run_if` / `skip_if`)\n",
    "\n",
    "Accrue pipelines often need to skip steps for certain rows based on data conditions:\n",
    "- \"Only run credit check for US companies\"\n",
    "- \"Skip deep research if the classifier said 'irrelevant'\"\n",
    "- \"Only call the expensive LLM step for high-priority leads\"\n",
    "\n",
    "Both `LLMStep` and `FunctionStep` accept `run_if` and `skip_if` predicates.\n",
    "These are evaluated **per-row** before the step executes.\n",
    "\n",
    "- `run_if`: Step runs only when the predicate returns `True`\n",
    "- `skip_if`: Step is skipped when the predicate returns `True`\n",
    "- They are **mutually exclusive** (use one or the other)\n",
    "- Skipped rows get `None` values (or field spec `default` where available)\n",
    "- Skipped rows **never hit cache** or call `step.run()`\n",
    "\n",
    "**Predicate signature:** `(row: dict, prior_results: dict) -> bool`\n",
    "\n",
    "> All examples below use `FunctionStep` so they run without an API key.\n",
    "> `LLMStep` works identically — just add `run_if`/`skip_if` to the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accrue import Pipeline, FunctionStep, LLMStep, EnrichmentConfig, EnrichmentHooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s1-header",
   "metadata": {},
   "source": [
    "## 1. Basic `run_if` — filter rows by data\n",
    "\n",
    "The simplest case: only run a step for rows matching a condition.\n",
    "Rows that don't match get `None` for all output fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s1-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\"company\": \"Acme Corp\", \"country\": \"US\"},\n",
    "    {\"company\": \"Beta GmbH\", \"country\": \"DE\"},\n",
    "    {\"company\": \"Gamma Inc\", \"country\": \"US\"},\n",
    "    {\"company\": \"Delta Ltd\", \"country\": \"UK\"},\n",
    "]\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    FunctionStep(\n",
    "        \"us_check\",\n",
    "        fn=lambda ctx: {\"credit_score\": f\"{ctx.row['company']}: AAA\"},\n",
    "        fields=[\"credit_score\"],\n",
    "        run_if=lambda row, prior: row[\"country\"] == \"US\",\n",
    "    )\n",
    "])\n",
    "\n",
    "config = EnrichmentConfig(enable_progress_bar=False)\n",
    "result = await pipeline.run_async(data, config)\n",
    "\n",
    "for row in result.data:\n",
    "    status = row['credit_score'] or '(skipped)'\n",
    "    print(f\"  {row['company']:12s} [{row['country']}] -> {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s2-header",
   "metadata": {},
   "source": [
    "## 2. `skip_if` — the inverse\n",
    "\n",
    "`skip_if` is the opposite of `run_if`: the step is **skipped** when the predicate returns `True`.\n",
    "Use whichever reads more naturally for your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s2-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    FunctionStep(\n",
    "        \"non_us_enrichment\",\n",
    "        fn=lambda ctx: {\"local_reg\": f\"{ctx.row['country']} regulations apply\"},\n",
    "        fields=[\"local_reg\"],\n",
    "        skip_if=lambda row, prior: row[\"country\"] == \"US\",\n",
    "    )\n",
    "])\n",
    "\n",
    "result = await pipeline.run_async(data, config)\n",
    "\n",
    "for row in result.data:\n",
    "    status = row['local_reg'] or '(skipped — US company)'\n",
    "    print(f\"  {row['company']:12s} [{row['country']}] -> {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s3-header",
   "metadata": {},
   "source": [
    "## 3. Predicates using `prior_results`\n",
    "\n",
    "The predicate receives `(row, prior_results)` — so downstream steps can branch\n",
    "based on what upstream steps produced. This is the **conditional pipeline** pattern:\n",
    "classify first, then only run expensive steps for rows that need them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s3-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads = [\n",
    "    {\"company\": \"Stripe\",    \"annual_revenue\": 15_000_000_000},\n",
    "    {\"company\": \"Joe's Deli\", \"annual_revenue\": 500_000},\n",
    "    {\"company\": \"Notion\",    \"annual_revenue\": 1_000_000_000},\n",
    "    {\"company\": \"Corner Shop\", \"annual_revenue\": 200_000},\n",
    "]\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    # Step 1: classify every lead (cheap / fast)\n",
    "    FunctionStep(\n",
    "        \"classify\",\n",
    "        fn=lambda ctx: {\n",
    "            \"tier\": \"enterprise\" if ctx.row[\"annual_revenue\"] > 10_000_000 else \"smb\"\n",
    "        },\n",
    "        fields=[\"tier\"],\n",
    "    ),\n",
    "    # Step 2: only run deep research for enterprise leads\n",
    "    FunctionStep(\n",
    "        \"deep_research\",\n",
    "        fn=lambda ctx: {\"research\": f\"Deep analysis of {ctx.row['company']}\"},\n",
    "        fields=[\"research\"],\n",
    "        depends_on=[\"classify\"],\n",
    "        run_if=lambda row, prior: prior.get(\"tier\") == \"enterprise\",\n",
    "    ),\n",
    "])\n",
    "\n",
    "result = await pipeline.run_async(leads, config)\n",
    "\n",
    "for row in result.data:\n",
    "    research = row['research'] or '(skipped — SMB)'\n",
    "    print(f\"  {row['company']:12s} tier={row['tier']:10s} -> {research}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s4-header",
   "metadata": {},
   "source": [
    "## 4. Skipped rows flow to downstream steps\n",
    "\n",
    "Skipped rows produce `None` (or field defaults) as their output values.\n",
    "Downstream steps see these values in `prior_results` — so you can chain\n",
    "conditional logic across multiple steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s4-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    FunctionStep(\n",
    "        \"classify\",\n",
    "        fn=lambda ctx: {\"label\": \"relevant\"},\n",
    "        fields=[\"label\"],\n",
    "        run_if=lambda row, prior: row[\"score\"] > 5,\n",
    "    ),\n",
    "    # This step runs for ALL rows — it sees label=None for skipped rows\n",
    "    FunctionStep(\n",
    "        \"summarize\",\n",
    "        fn=lambda ctx: {\n",
    "            \"summary\": f\"label={ctx.prior_results.get('label')}, score={ctx.row['score']}\"\n",
    "        },\n",
    "        fields=[\"summary\"],\n",
    "        depends_on=[\"classify\"],\n",
    "    ),\n",
    "])\n",
    "\n",
    "result = await pipeline.run_async(\n",
    "    [{\"score\": 10}, {\"score\": 2}, {\"score\": 8}], config\n",
    ")\n",
    "\n",
    "for row in result.data:\n",
    "    print(f\"  score={row['score']:2d}  label={str(row['label']):>10s}  summary={row['summary']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s5-header",
   "metadata": {},
   "source": [
    "## 5. `rows_skipped` in usage stats\n",
    "\n",
    "`StepUsage` now includes a `rows_skipped` counter so you can see exactly\n",
    "how many rows were skipped vs executed vs cached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s5-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    FunctionStep(\n",
    "        \"expensive_step\",\n",
    "        fn=lambda ctx: {\"result\": \"done\"},\n",
    "        fields=[\"result\"],\n",
    "        run_if=lambda row, prior: row[\"priority\"] == \"high\",\n",
    "    )\n",
    "])\n",
    "\n",
    "data = [\n",
    "    {\"id\": 1, \"priority\": \"high\"},\n",
    "    {\"id\": 2, \"priority\": \"low\"},\n",
    "    {\"id\": 3, \"priority\": \"low\"},\n",
    "    {\"id\": 4, \"priority\": \"high\"},\n",
    "    {\"id\": 5, \"priority\": \"low\"},\n",
    "]\n",
    "\n",
    "result = await pipeline.run_async(data, config)\n",
    "\n",
    "usage = result.cost.steps[\"expensive_step\"]\n",
    "rows_executed = len(data) - usage.rows_skipped\n",
    "print(f\"Total rows:    {len(data)}\")\n",
    "print(f\"rows_skipped:  {usage.rows_skipped}\")\n",
    "print(f\"rows_executed: {rows_executed}\")\n",
    "print(f\"\\nSkipping saved {usage.rows_skipped}/{len(data)} step executions ({usage.rows_skipped/len(data):.0%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s6-header",
   "metadata": {},
   "source": [
    "## 6. Hooks: `skipped` flag on `RowCompleteEvent`\n",
    "\n",
    "`RowCompleteEvent` now includes `skipped: bool` so observability hooks\n",
    "can distinguish skipped rows from executed rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s6-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accrue.core.hooks import RowCompleteEvent\n",
    "\n",
    "events: list[RowCompleteEvent] = []\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    FunctionStep(\n",
    "        \"check\",\n",
    "        fn=lambda ctx: {\"status\": \"checked\"},\n",
    "        fields=[\"status\"],\n",
    "        run_if=lambda row, prior: row[\"country\"] == \"US\",\n",
    "    )\n",
    "])\n",
    "\n",
    "hooks = EnrichmentHooks(on_row_complete=lambda e: events.append(e))\n",
    "await pipeline.run_async(\n",
    "    [{\"country\": \"US\"}, {\"country\": \"UK\"}, {\"country\": \"US\"}],\n",
    "    config,\n",
    "    hooks=hooks,\n",
    ")\n",
    "\n",
    "for e in sorted(events, key=lambda e: e.row_index):\n",
    "    print(f\"  Row {e.row_index}: skipped={e.skipped}, values={e.values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s7-header",
   "metadata": {},
   "source": [
    "## 7. Caching interaction\n",
    "\n",
    "Skipped rows **never create cache entries**. The skip decision is deterministic\n",
    "from the predicate — same inputs always produce the same skip decision.\n",
    "Non-skipped rows are cached normally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s7-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "cache_dir = tempfile.mkdtemp()\n",
    "call_count = 0\n",
    "\n",
    "def counting_fn(ctx):\n",
    "    global call_count\n",
    "    call_count += 1\n",
    "    return {\"result\": f\"processed {ctx.row['name']}\"}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    FunctionStep(\n",
    "        \"process\",\n",
    "        fn=counting_fn,\n",
    "        fields=[\"result\"],\n",
    "        run_if=lambda row, prior: row[\"active\"],\n",
    "    )\n",
    "])\n",
    "\n",
    "cache_config = EnrichmentConfig(\n",
    "    enable_caching=True,\n",
    "    cache_dir=cache_dir,\n",
    "    enable_progress_bar=False,\n",
    ")\n",
    "\n",
    "rows = [\n",
    "    {\"name\": \"Alice\", \"active\": True},\n",
    "    {\"name\": \"Bob\",   \"active\": False},\n",
    "    {\"name\": \"Carol\", \"active\": True},\n",
    "]\n",
    "\n",
    "# First run: only active rows execute\n",
    "call_count = 0\n",
    "r1 = await pipeline.run_async(rows, cache_config)\n",
    "u1 = r1.cost.steps[\"process\"]\n",
    "print(f\"Run 1: fn called {call_count}x, cache_hits={u1.cache_hits}, \"\n",
    "      f\"cache_misses={u1.cache_misses}, rows_skipped={u1.rows_skipped}\")\n",
    "\n",
    "# Second run: active rows served from cache, inactive still skipped\n",
    "call_count = 0\n",
    "r2 = await pipeline.run_async(rows, cache_config)\n",
    "u2 = r2.cost.steps[\"process\"]\n",
    "print(f\"Run 2: fn called {call_count}x, cache_hits={u2.cache_hits}, \"\n",
    "      f\"cache_misses={u2.cache_misses}, rows_skipped={u2.rows_skipped}\")\n",
    "\n",
    "# Cleanup\n",
    "import shutil\n",
    "shutil.rmtree(cache_dir, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s8-header",
   "metadata": {},
   "source": [
    "## 8. Mutual exclusivity validation\n",
    "\n",
    "Setting both `run_if` and `skip_if` on the same step raises `PipelineError` at construction time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s8-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accrue.core.exceptions import PipelineError\n",
    "\n",
    "try:\n",
    "    FunctionStep(\n",
    "        \"bad\",\n",
    "        fn=lambda ctx: {},\n",
    "        fields=[\"f\"],\n",
    "        run_if=lambda row, prior: True,\n",
    "        skip_if=lambda row, prior: False,\n",
    "    )\n",
    "except PipelineError as e:\n",
    "    print(f\"Caught at construction time (as expected):\\n  {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s9-header",
   "metadata": {},
   "source": [
    "## 9. Async predicates\n",
    "\n",
    "Both sync and async predicates are supported. Async predicates are awaited automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s9-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def check_eligibility(row, prior):\n",
    "    \"\"\"Simulate an async eligibility check (e.g. database lookup).\"\"\"\n",
    "    await asyncio.sleep(0)  # simulate I/O\n",
    "    return row.get(\"eligible\", False)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    FunctionStep(\n",
    "        \"enroll\",\n",
    "        fn=lambda ctx: {\"enrolled\": True},\n",
    "        fields=[\"enrolled\"],\n",
    "        run_if=check_eligibility,\n",
    "    )\n",
    "])\n",
    "\n",
    "result = await pipeline.run_async(\n",
    "    [{\"name\": \"Alice\", \"eligible\": True}, {\"name\": \"Bob\", \"eligible\": False}],\n",
    "    config,\n",
    ")\n",
    "\n",
    "for row in result.data:\n",
    "    print(f\"  {row['name']}: enrolled={row['enrolled']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s10-header",
   "metadata": {},
   "source": [
    "## 10. Real-world pattern: classify → conditional deep enrichment\n",
    "\n",
    "A common pipeline pattern: a cheap classifier decides which rows get expensive enrichment.\n",
    "This saves API calls and cost for rows that don't need them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s10-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = [\n",
    "    {\"company\": \"Stripe\",       \"sector\": \"fintech\",      \"country\": \"US\"},\n",
    "    {\"company\": \"Klarna\",       \"sector\": \"fintech\",      \"country\": \"SE\"},\n",
    "    {\"company\": \"Notion\",       \"sector\": \"productivity\", \"country\": \"US\"},\n",
    "    {\"company\": \"Spotify\",      \"sector\": \"media\",        \"country\": \"SE\"},\n",
    "    {\"company\": \"Canva\",        \"sector\": \"design\",       \"country\": \"AU\"},\n",
    "]\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    # Step 1: tag every row (cheap, runs for all)\n",
    "    FunctionStep(\n",
    "        \"tag\",\n",
    "        fn=lambda ctx: {\"is_target\": ctx.row[\"sector\"] == \"fintech\" and ctx.row[\"country\"] == \"US\"},\n",
    "        fields=[\"is_target\"],\n",
    "    ),\n",
    "    # Step 2: only enrich target companies\n",
    "    FunctionStep(\n",
    "        \"enrich\",\n",
    "        fn=lambda ctx: {\n",
    "            \"analysis\": f\"{ctx.row['company']}: US fintech deep-dive complete\",\n",
    "            \"risk_score\": 42,\n",
    "        },\n",
    "        fields=[\"analysis\", \"risk_score\"],\n",
    "        depends_on=[\"tag\"],\n",
    "        run_if=lambda row, prior: prior.get(\"is_target\") is True,\n",
    "    ),\n",
    "])\n",
    "\n",
    "result = await pipeline.run_async(companies, config)\n",
    "\n",
    "print(f\"{'Company':12s} {'Sector':14s} {'Country':8s} {'Target':8s} {'Analysis'}\")\n",
    "print(\"-\" * 75)\n",
    "for row in result.data:\n",
    "    analysis = row.get('analysis') or '(skipped)'\n",
    "    print(f\"{row['company']:12s} {row['sector']:14s} {row['country']:8s} \"\n",
    "          f\"{str(row['is_target']):8s} {analysis}\")\n",
    "\n",
    "usage = result.cost.steps.get(\"enrich\")\n",
    "if usage:\n",
    "    print(f\"\\nEnrich step: {usage.rows_skipped} of {len(companies)} rows skipped\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
